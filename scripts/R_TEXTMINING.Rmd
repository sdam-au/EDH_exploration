---
title: "Exploration of the epigraphic text using TidyText approach"
author: "Petra Hermankova"
date: "26/10/2020"
output:
  html_document:
    theme: united
    toc: yes
    toc_float: true
    number_sections: true
    toc_depth: 2
    df_print: paged
---

# Initial setup

## Setup of the environment:

```{r setup, echo=TRUE, message=FALSE}
devtools::install_github("sdam-au/sdam") # loading SDAM custom package, if not working try devtools::install_github("mplex/cedhar", subdir="pkg/sdam")
#devtools::install_github("mplex/cedhar", subdir="pkg/sdam")
library(tidyverse)
library(sdam)
library(jsonlite)
library(leaflet)
library(tidytext)
library(udpipe)
```

## Loading data
1. Load the dataset, if you have Sciencedata.dk credentials

```{r, echo=FALSE}
mycred_secret<- readLines("~/mysecret.txt")
```

```{r, loading data}
resp = request("EDH_text_cleaned_2020-10-09.json", path="/sharingin/648597@au.dk/SDAM_root/SDAM_data/EDH/public", method="GET", cred=mycred_secret)
```

```{r, echo=FALSE}
remove(mycred_secret)
```

2. Make a list and tibble from the request function
```{r}
list_json <- jsonlite::fromJSON(resp)
EDH_tibble <- as_tibble(list_json)
```

3. Display the first 6 records
```{r}
head(EDH_tibble)
```

# Text mining using udpipe package
source: https://cran.r-project.org/web/packages/udpipe/vignettes/udpipe-annotation.html#udpipe_-_general

## Download model for given language
```{r}
#dl <- udpipe_download_model(language = "ancient_greek")
dl <- udpipe_download_model(language = "latin")
str(dl)
```

## Give the full path to the model and load it to R
```{r}
# udmodel_anc_greek <- udpipe_load_model(file = "ancient_greek-perseus-ud-2.4-190531.udpipe")

udmodel_latin <- udpipe_load_model(file = "latin-perseus-ud-2.4-190531.udpipe")
```

## Anotate the text using UDpipe
```{r}
#udpipe_text <- as.data.frame(udpipe_annotate(udmodel_anc_greek, x = EDH_tibble$clean_text_interpretive_word))
udpipe_text <- as.data.frame(udpipe_annotate(udmodel_latin, x = EDH_tibble$clean_text_interpretive_word))
str(udpipe_text)
```

## Overview of linguistic word categories
```{r}
table(udpipe_text$upos)
```

```{r}
nouns <- udpipe_text %>% 
  filter(udpipe_text$upos == "NOUN") 
```

```{r}
verbs <- udpipe_text %>% 
  filter(udpipe_text$upos == "VERB") 
```

```{r}
punctuation <- udpipe_text %>% 
  filter(udpipe_text$upos == "PUNCT") 
```

## The most frequent of all word lemmata
```{r}
udpipe_text %>% 
  count(lemma, sort = TRUE) %>%
  filter(n > 1000) %>% 
  mutate(lemma = reorder(lemma, n)) %>%
  print()
```

## The most frequent of nouns lemmata
```{r}
nouns %>% 
  count(lemma, sort = TRUE) %>%
  filter(n > 1000) %>% 
  mutate(lemma = reorder(lemma, n)) %>%
  print()
```

```{r}
verbs %>% 
  count(lemma, sort = TRUE) %>%
  filter(n > 1000) %>% 
  mutate(lemma = reorder(lemma, n)) %>%
  print()
```

```{r}
punctuation %>% 
  count(lemma, sort = TRUE) %>%
  filter(n > 10) %>% 
  mutate(lemma = reorder(lemma, n)) %>%
  print()
```


## Join the entire dataset with the NLP UD pipe output
```{r}
tail(udpipe_text)
udpipe_text <- udpipe_text %>% 
  mutate(insc_id = (as.numeric(str_replace(doc_id, pattern = "doc", replacement = ""))))

EDH_tibble <- EDH_tibble %>% 
  mutate(id_num = (as.numeric(str_replace(id, pattern = "HD", replacement = ""))))

full_appended <- left_join(EDH_tibble, udpipe_text, by = c("id_num" = "insc_id"))
head(full_appended)
```


# Search for Road-related inscription

## Defining road related vocabulary
```{r}
road_vocabulary1 <- c("via", "pons", "mutatio", "mansio", "caput viae", "miliarium", "millia passuum", "passus", "carpentum", "porta", "vicus", "clivus", "semita", "angiportus", "scala", "gradus", "gressus", "incessus", "leuga", "tabellarium", "tabelarium", "itinerarium", "annona", "actus", "cursus publicus", "vehiculatio", "vehiculum", "iter", "iumentum", "Via publica", "Via privata", "Via vicinalis", "Via terrena", "viam munire", "viam fecit", "viam refecit", "viam restituit", "curator viarum", "compitum", "deverticulum", "diverticulum", "civitas", "viator", "arcus", "statio", "terminus", "lares viales", "lares compitales", "Redicolus", "Ianus")

road_vocabulary2 <- c("παροδεῖτα")
```

## Searching for predefined vocabulary in lemmata
```{r}
full_appended %>%
  count(lemma, sort = TRUE) %>%
  filter(lemma %in% road_vocabulary1) %>% 
  print()
```

### Separating the subdataset containing the predefined vocabulary
```{r}
road_text <- full_appended %>%
  filter(lemma %in% road_vocabulary1) %>% 
  print()
```

### What type of inscriptions contain selected vocabulary
```{r}
road_text %>% 
  count(type_of_inscription_clean, sort=TRUE)
```

### What are the most common words (lemma and token)
```{r}
road_text %>% 
  count(lemma, token, sort=TRUE)
```

### How many unique inscriptions there are
```{r}
length(unique(road_text$id_num))
```

### Select only the text of inscriptions once
```{r}
road_text %>% 
  select(id_num, clean_text_interpretive_word) %>% 
  distinct(id_num, .keep_all = TRUE)
```

